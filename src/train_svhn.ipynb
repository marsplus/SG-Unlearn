{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/train_32x32.mat\n",
      "Using downloaded and verified file: ./data/test_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model_ft = resnet18(num_classes=10)\n",
    "model_ft.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "trainingBatchSize = 128\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.SVHN(\n",
    "    root=\"./data\", split=\"train\", download=True, transform=transform_train\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=trainingBatchSize, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.SVHN(\n",
    "    root=\"./data\", split=\"test\", download=True, transform=transform_test\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2\n",
    ")  ##test batch size is kept fized at 100 and not varied\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, epoch, l1=False):\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.cuda()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    start = time.time()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 0.01)\n",
    "\n",
    "    for j in range(epoch):\n",
    "        for i, (image, target) in enumerate(train_loader):\n",
    "\n",
    "            image = image.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output_clean = model(image)\n",
    "\n",
    "            loss = criterion(output_clean, target)\n",
    "            # if l1:\n",
    "            #     loss = loss + args.alpha * l1_regularization(model)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            output = output_clean.float()\n",
    "            loss = loss.float()\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(output.data, target)[0]\n",
    "\n",
    "            losses.update(loss.item(), image.size(0))\n",
    "            top1.update(prec1.item(), image.size(0))\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                end = time.time()\n",
    "                print(\n",
    "                    \"Epoch: [{0}][{1}/{2}]\\t\"\n",
    "                    \"Loss {loss.val:.4f} ({loss.avg:.4f})\\t\"\n",
    "                    \"Accuracy {top1.val:.3f} ({top1.avg:.3f})\\t\"\n",
    "                    \"Time {3:.2f}\".format(\n",
    "                        j, i, len(train_loader), end - start, loss=losses, top1=top1\n",
    "                    )\n",
    "                )\n",
    "                start = time.time()\n",
    "\n",
    "        print(\"train_accuracy {top1.avg:.3f}\".format(top1=top1))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][99/573]\tLoss 2.2203 (2.2663)\tAccuracy 21.875 (17.453)\tTime 1.84\n",
      "Epoch: [0][199/573]\tLoss 2.2673 (2.2575)\tAccuracy 20.312 (17.914)\tTime 1.60\n",
      "Epoch: [0][299/573]\tLoss 2.2781 (2.2469)\tAccuracy 15.625 (18.565)\tTime 1.62\n",
      "Epoch: [0][399/573]\tLoss 2.1041 (2.2283)\tAccuracy 26.562 (19.672)\tTime 1.62\n",
      "Epoch: [0][499/573]\tLoss 1.9619 (2.1928)\tAccuracy 30.469 (21.238)\tTime 1.86\n",
      "train_accuracy 22.585\n",
      "Epoch: [1][99/573]\tLoss 1.7700 (2.1049)\tAccuracy 36.719 (24.821)\tTime 3.11\n",
      "Epoch: [1][199/573]\tLoss 1.7137 (2.0468)\tAccuracy 42.188 (27.113)\tTime 1.54\n",
      "Epoch: [1][299/573]\tLoss 1.4109 (1.9888)\tAccuracy 50.781 (29.281)\tTime 1.53\n",
      "Epoch: [1][399/573]\tLoss 1.4635 (1.9353)\tAccuracy 50.781 (31.276)\tTime 1.72\n",
      "Epoch: [1][499/573]\tLoss 1.3859 (1.8873)\tAccuracy 52.344 (33.075)\tTime 1.91\n",
      "train_accuracy 34.363\n",
      "Epoch: [2][99/573]\tLoss 1.2328 (1.8075)\tAccuracy 53.906 (36.091)\tTime 3.34\n",
      "Epoch: [2][199/573]\tLoss 1.1592 (1.7638)\tAccuracy 55.469 (37.709)\tTime 1.60\n",
      "Epoch: [2][299/573]\tLoss 1.2728 (1.7232)\tAccuracy 55.469 (39.221)\tTime 1.75\n",
      "Epoch: [2][399/573]\tLoss 1.1295 (1.6844)\tAccuracy 58.594 (40.662)\tTime 1.61\n",
      "Epoch: [2][499/573]\tLoss 0.9209 (1.6474)\tAccuracy 69.531 (42.056)\tTime 1.87\n",
      "train_accuracy 43.013\n",
      "Epoch: [3][99/573]\tLoss 1.1365 (1.5873)\tAccuracy 60.156 (44.308)\tTime 3.29\n",
      "Epoch: [3][199/573]\tLoss 1.1427 (1.5548)\tAccuracy 63.281 (45.522)\tTime 1.96\n",
      "Epoch: [3][299/573]\tLoss 0.7961 (1.5227)\tAccuracy 70.312 (46.704)\tTime 1.64\n",
      "Epoch: [3][399/573]\tLoss 0.9552 (1.4928)\tAccuracy 69.531 (47.833)\tTime 1.59\n",
      "Epoch: [3][499/573]\tLoss 0.8408 (1.4639)\tAccuracy 71.875 (48.918)\tTime 1.68\n",
      "train_accuracy 49.674\n",
      "Epoch: [4][99/573]\tLoss 0.6101 (1.4165)\tAccuracy 79.688 (50.678)\tTime 3.07\n",
      "Epoch: [4][199/573]\tLoss 0.8298 (1.3905)\tAccuracy 68.750 (51.639)\tTime 1.63\n",
      "Epoch: [4][299/573]\tLoss 0.6952 (1.3658)\tAccuracy 75.781 (52.535)\tTime 1.94\n",
      "Epoch: [4][399/573]\tLoss 0.7970 (1.3418)\tAccuracy 73.438 (53.422)\tTime 1.70\n",
      "Epoch: [4][499/573]\tLoss 0.7030 (1.3190)\tAccuracy 77.344 (54.265)\tTime 1.66\n",
      "train_accuracy 54.867\n",
      "Epoch: [5][99/573]\tLoss 0.7045 (1.2815)\tAccuracy 71.875 (55.650)\tTime 3.27\n",
      "Epoch: [5][199/573]\tLoss 0.7490 (1.2612)\tAccuracy 75.000 (56.406)\tTime 1.65\n",
      "Epoch: [5][299/573]\tLoss 0.6078 (1.2420)\tAccuracy 78.906 (57.104)\tTime 1.67\n",
      "Epoch: [5][399/573]\tLoss 0.5771 (1.2229)\tAccuracy 84.375 (57.813)\tTime 1.76\n",
      "Epoch: [5][499/573]\tLoss 0.6684 (1.2049)\tAccuracy 77.344 (58.477)\tTime 1.91\n",
      "train_accuracy 58.942\n",
      "Epoch: [6][99/573]\tLoss 0.6086 (1.1748)\tAccuracy 82.031 (59.569)\tTime 3.49\n",
      "Epoch: [6][199/573]\tLoss 0.5348 (1.1584)\tAccuracy 83.594 (60.166)\tTime 1.78\n",
      "Epoch: [6][299/573]\tLoss 0.6750 (1.1426)\tAccuracy 78.125 (60.751)\tTime 1.69\n",
      "Epoch: [6][399/573]\tLoss 0.6438 (1.1276)\tAccuracy 79.688 (61.298)\tTime 1.87\n",
      "Epoch: [6][499/573]\tLoss 0.6388 (1.1132)\tAccuracy 78.906 (61.819)\tTime 1.69\n",
      "train_accuracy 62.185\n",
      "Epoch: [7][99/573]\tLoss 0.4896 (1.0893)\tAccuracy 83.594 (62.681)\tTime 3.39\n",
      "Epoch: [7][199/573]\tLoss 0.6317 (1.0759)\tAccuracy 80.469 (63.166)\tTime 1.64\n",
      "Epoch: [7][299/573]\tLoss 0.4962 (1.0631)\tAccuracy 83.594 (63.636)\tTime 1.63\n",
      "Epoch: [7][399/573]\tLoss 0.3814 (1.0502)\tAccuracy 86.719 (64.097)\tTime 1.60\n",
      "Epoch: [7][499/573]\tLoss 0.5880 (1.0384)\tAccuracy 77.344 (64.531)\tTime 1.73\n",
      "train_accuracy 64.839\n",
      "Epoch: [8][99/573]\tLoss 0.4651 (1.0183)\tAccuracy 84.375 (65.255)\tTime 3.03\n",
      "Epoch: [8][199/573]\tLoss 0.4629 (1.0074)\tAccuracy 82.812 (65.657)\tTime 1.63\n",
      "Epoch: [8][299/573]\tLoss 0.5719 (0.9965)\tAccuracy 84.375 (66.049)\tTime 1.69\n",
      "Epoch: [8][399/573]\tLoss 0.4948 (0.9860)\tAccuracy 78.906 (66.428)\tTime 1.53\n",
      "Epoch: [8][499/573]\tLoss 0.5418 (0.9758)\tAccuracy 79.688 (66.797)\tTime 2.00\n",
      "train_accuracy 67.053\n",
      "Epoch: [9][99/573]\tLoss 0.6531 (0.9590)\tAccuracy 82.031 (67.403)\tTime 3.60\n",
      "Epoch: [9][199/573]\tLoss 0.4492 (0.9497)\tAccuracy 84.375 (67.739)\tTime 1.82\n",
      "Epoch: [9][299/573]\tLoss 0.4755 (0.9406)\tAccuracy 85.938 (68.073)\tTime 1.90\n",
      "Epoch: [9][399/573]\tLoss 0.6552 (0.9319)\tAccuracy 83.594 (68.387)\tTime 1.80\n",
      "Epoch: [9][499/573]\tLoss 0.5092 (0.9231)\tAccuracy 81.250 (68.699)\tTime 1.94\n",
      "train_accuracy 68.915\n",
      "Epoch: [10][99/573]\tLoss 0.4446 (0.9086)\tAccuracy 83.594 (69.218)\tTime 3.26\n",
      "Epoch: [10][199/573]\tLoss 0.5677 (0.9003)\tAccuracy 85.938 (69.514)\tTime 1.64\n",
      "Epoch: [10][299/573]\tLoss 0.4090 (0.8922)\tAccuracy 86.719 (69.799)\tTime 1.73\n",
      "Epoch: [10][399/573]\tLoss 0.6423 (0.8850)\tAccuracy 78.125 (70.062)\tTime 1.85\n",
      "Epoch: [10][499/573]\tLoss 0.3525 (0.8775)\tAccuracy 89.844 (70.335)\tTime 1.79\n",
      "train_accuracy 70.521\n",
      "Epoch: [11][99/573]\tLoss 0.4336 (0.8648)\tAccuracy 85.156 (70.783)\tTime 3.26\n",
      "Epoch: [11][199/573]\tLoss 0.3034 (0.8579)\tAccuracy 90.625 (71.037)\tTime 1.71\n",
      "Epoch: [11][299/573]\tLoss 0.3847 (0.8508)\tAccuracy 85.156 (71.287)\tTime 1.86\n",
      "Epoch: [11][399/573]\tLoss 0.4458 (0.8443)\tAccuracy 81.250 (71.518)\tTime 1.71\n",
      "Epoch: [11][499/573]\tLoss 0.6059 (0.8381)\tAccuracy 83.594 (71.747)\tTime 1.92\n",
      "train_accuracy 71.917\n",
      "Epoch: [12][99/573]\tLoss 0.3120 (0.8272)\tAccuracy 92.188 (72.137)\tTime 3.07\n",
      "Epoch: [12][199/573]\tLoss 0.4337 (0.8209)\tAccuracy 85.156 (72.360)\tTime 1.74\n",
      "Epoch: [12][299/573]\tLoss 0.4524 (0.8148)\tAccuracy 85.938 (72.577)\tTime 1.64\n",
      "Epoch: [12][399/573]\tLoss 0.3969 (0.8090)\tAccuracy 90.625 (72.786)\tTime 1.73\n",
      "Epoch: [12][499/573]\tLoss 0.4474 (0.8031)\tAccuracy 86.719 (72.996)\tTime 1.67\n",
      "train_accuracy 73.143\n",
      "Epoch: [13][99/573]\tLoss 0.4782 (0.7934)\tAccuracy 84.375 (73.345)\tTime 3.35\n",
      "Epoch: [13][199/573]\tLoss 0.3810 (0.7878)\tAccuracy 89.062 (73.540)\tTime 1.62\n",
      "Epoch: [13][299/573]\tLoss 0.4952 (0.7826)\tAccuracy 87.500 (73.735)\tTime 1.66\n",
      "Epoch: [13][399/573]\tLoss 0.5676 (0.7773)\tAccuracy 82.031 (73.923)\tTime 1.57\n",
      "Epoch: [13][499/573]\tLoss 0.2866 (0.7721)\tAccuracy 95.312 (74.110)\tTime 1.80\n",
      "train_accuracy 74.237\n",
      "Epoch: [14][99/573]\tLoss 0.4545 (0.7636)\tAccuracy 88.281 (74.412)\tTime 3.23\n",
      "Epoch: [14][199/573]\tLoss 0.2464 (0.7587)\tAccuracy 91.406 (74.589)\tTime 1.87\n",
      "Epoch: [14][299/573]\tLoss 0.4727 (0.7539)\tAccuracy 87.500 (74.760)\tTime 1.59\n",
      "Epoch: [14][399/573]\tLoss 0.3086 (0.7492)\tAccuracy 90.625 (74.927)\tTime 1.58\n",
      "Epoch: [14][499/573]\tLoss 0.3582 (0.7446)\tAccuracy 85.938 (75.091)\tTime 1.60\n",
      "train_accuracy 75.209\n",
      "Epoch: [15][99/573]\tLoss 0.4316 (0.7367)\tAccuracy 86.719 (75.376)\tTime 3.10\n",
      "Epoch: [15][199/573]\tLoss 0.4758 (0.7324)\tAccuracy 86.719 (75.526)\tTime 1.57\n",
      "Epoch: [15][299/573]\tLoss 0.3365 (0.7281)\tAccuracy 89.062 (75.681)\tTime 1.80\n",
      "Epoch: [15][399/573]\tLoss 0.2905 (0.7239)\tAccuracy 90.625 (75.836)\tTime 1.69\n",
      "Epoch: [15][499/573]\tLoss 0.2276 (0.7198)\tAccuracy 93.750 (75.981)\tTime 1.97\n",
      "train_accuracy 76.088\n",
      "Epoch: [16][99/573]\tLoss 0.2811 (0.7126)\tAccuracy 89.844 (76.235)\tTime 3.78\n",
      "Epoch: [16][199/573]\tLoss 0.3272 (0.7085)\tAccuracy 88.281 (76.379)\tTime 1.65\n",
      "Epoch: [16][299/573]\tLoss 0.2525 (0.7046)\tAccuracy 92.969 (76.515)\tTime 1.60\n",
      "Epoch: [16][399/573]\tLoss 0.2621 (0.7008)\tAccuracy 92.969 (76.650)\tTime 1.75\n",
      "Epoch: [16][499/573]\tLoss 0.3399 (0.6971)\tAccuracy 88.281 (76.782)\tTime 1.65\n",
      "train_accuracy 76.879\n",
      "Epoch: [17][99/573]\tLoss 0.2679 (0.6906)\tAccuracy 89.844 (77.015)\tTime 3.53\n",
      "Epoch: [17][199/573]\tLoss 0.3376 (0.6870)\tAccuracy 88.281 (77.145)\tTime 1.69\n",
      "Epoch: [17][299/573]\tLoss 0.2928 (0.6835)\tAccuracy 89.062 (77.272)\tTime 1.58\n",
      "Epoch: [17][399/573]\tLoss 0.3460 (0.6799)\tAccuracy 89.062 (77.401)\tTime 1.76\n",
      "Epoch: [17][499/573]\tLoss 0.2932 (0.6766)\tAccuracy 90.625 (77.521)\tTime 1.94\n",
      "train_accuracy 77.605\n",
      "Epoch: [18][99/573]\tLoss 0.3065 (0.6708)\tAccuracy 91.406 (77.725)\tTime 3.25\n",
      "Epoch: [18][199/573]\tLoss 0.4227 (0.6675)\tAccuracy 92.188 (77.843)\tTime 1.72\n",
      "Epoch: [18][299/573]\tLoss 0.3319 (0.6642)\tAccuracy 92.188 (77.961)\tTime 1.69\n",
      "Epoch: [18][399/573]\tLoss 0.4517 (0.6608)\tAccuracy 88.281 (78.078)\tTime 1.54\n",
      "Epoch: [18][499/573]\tLoss 0.2313 (0.6578)\tAccuracy 92.969 (78.186)\tTime 1.64\n",
      "train_accuracy 78.268\n",
      "Epoch: [19][99/573]\tLoss 0.2230 (0.6523)\tAccuracy 91.406 (78.378)\tTime 3.41\n",
      "Epoch: [19][199/573]\tLoss 0.3589 (0.6494)\tAccuracy 89.844 (78.484)\tTime 1.66\n",
      "Epoch: [19][299/573]\tLoss 0.3591 (0.6464)\tAccuracy 87.500 (78.590)\tTime 1.68\n",
      "Epoch: [19][399/573]\tLoss 0.3004 (0.6433)\tAccuracy 92.188 (78.695)\tTime 1.75\n",
      "Epoch: [19][499/573]\tLoss 0.1948 (0.6403)\tAccuracy 92.188 (78.806)\tTime 1.90\n",
      "train_accuracy 78.877\n",
      "Epoch: [20][99/573]\tLoss 0.2977 (0.6353)\tAccuracy 91.406 (78.982)\tTime 3.78\n",
      "Epoch: [20][199/573]\tLoss 0.2935 (0.6324)\tAccuracy 92.188 (79.083)\tTime 1.50\n",
      "Epoch: [20][299/573]\tLoss 0.1865 (0.6297)\tAccuracy 94.531 (79.181)\tTime 1.78\n",
      "Epoch: [20][399/573]\tLoss 0.4309 (0.6270)\tAccuracy 86.719 (79.274)\tTime 1.71\n",
      "Epoch: [20][499/573]\tLoss 0.2437 (0.6242)\tAccuracy 91.406 (79.371)\tTime 1.84\n",
      "train_accuracy 79.438\n",
      "Epoch: [21][99/573]\tLoss 0.1722 (0.6196)\tAccuracy 95.312 (79.535)\tTime 3.37\n",
      "Epoch: [21][199/573]\tLoss 0.2758 (0.6170)\tAccuracy 88.281 (79.625)\tTime 1.98\n",
      "Epoch: [21][299/573]\tLoss 0.3354 (0.6145)\tAccuracy 92.188 (79.717)\tTime 1.97\n",
      "Epoch: [21][399/573]\tLoss 0.2400 (0.6120)\tAccuracy 92.969 (79.807)\tTime 2.01\n",
      "Epoch: [21][499/573]\tLoss 0.1916 (0.6094)\tAccuracy 94.531 (79.898)\tTime 1.74\n",
      "train_accuracy 79.962\n",
      "Epoch: [22][99/573]\tLoss 0.3465 (0.6051)\tAccuracy 91.406 (80.047)\tTime 3.49\n",
      "Epoch: [22][199/573]\tLoss 0.2377 (0.6027)\tAccuracy 92.188 (80.133)\tTime 2.06\n",
      "Epoch: [22][299/573]\tLoss 0.4742 (0.6002)\tAccuracy 90.625 (80.221)\tTime 1.74\n",
      "Epoch: [22][399/573]\tLoss 0.3197 (0.5979)\tAccuracy 88.281 (80.304)\tTime 1.79\n",
      "Epoch: [22][499/573]\tLoss 0.2937 (0.5955)\tAccuracy 90.625 (80.387)\tTime 1.68\n",
      "train_accuracy 80.446\n",
      "Epoch: [23][99/573]\tLoss 0.3823 (0.5915)\tAccuracy 87.500 (80.526)\tTime 3.09\n",
      "Epoch: [23][199/573]\tLoss 0.2392 (0.5892)\tAccuracy 91.406 (80.608)\tTime 1.77\n",
      "Epoch: [23][299/573]\tLoss 0.3016 (0.5870)\tAccuracy 89.844 (80.685)\tTime 2.10\n",
      "Epoch: [23][399/573]\tLoss 0.2819 (0.5848)\tAccuracy 89.844 (80.761)\tTime 1.73\n",
      "Epoch: [23][499/573]\tLoss 0.1676 (0.5826)\tAccuracy 96.094 (80.838)\tTime 1.97\n",
      "train_accuracy 80.895\n",
      "Epoch: [24][99/573]\tLoss 0.1815 (0.5788)\tAccuracy 92.188 (80.974)\tTime 3.18\n",
      "Epoch: [24][199/573]\tLoss 0.3798 (0.5766)\tAccuracy 88.281 (81.051)\tTime 1.61\n",
      "Epoch: [24][299/573]\tLoss 0.2501 (0.5745)\tAccuracy 91.406 (81.125)\tTime 1.66\n",
      "Epoch: [24][399/573]\tLoss 0.4672 (0.5725)\tAccuracy 85.938 (81.195)\tTime 1.93\n",
      "Epoch: [24][499/573]\tLoss 0.3447 (0.5705)\tAccuracy 91.406 (81.264)\tTime 1.63\n",
      "train_accuracy 81.317\n",
      "Epoch: [25][99/573]\tLoss 0.2808 (0.5669)\tAccuracy 91.406 (81.388)\tTime 3.61\n",
      "Epoch: [25][199/573]\tLoss 0.2798 (0.5649)\tAccuracy 93.750 (81.463)\tTime 1.76\n",
      "Epoch: [25][299/573]\tLoss 0.2017 (0.5629)\tAccuracy 93.750 (81.532)\tTime 1.78\n",
      "Epoch: [25][399/573]\tLoss 0.1908 (0.5608)\tAccuracy 91.406 (81.603)\tTime 1.64\n",
      "Epoch: [25][499/573]\tLoss 0.2228 (0.5590)\tAccuracy 90.625 (81.670)\tTime 1.93\n",
      "train_accuracy 81.718\n",
      "Epoch: [26][99/573]\tLoss 0.2339 (0.5556)\tAccuracy 94.531 (81.789)\tTime 3.45\n",
      "Epoch: [26][199/573]\tLoss 0.3241 (0.5538)\tAccuracy 90.625 (81.857)\tTime 1.91\n",
      "Epoch: [26][299/573]\tLoss 0.1908 (0.5519)\tAccuracy 94.531 (81.921)\tTime 1.92\n",
      "Epoch: [26][399/573]\tLoss 0.3897 (0.5501)\tAccuracy 87.500 (81.987)\tTime 1.98\n",
      "Epoch: [26][499/573]\tLoss 0.2860 (0.5482)\tAccuracy 92.969 (82.051)\tTime 1.66\n",
      "train_accuracy 82.096\n",
      "Epoch: [27][99/573]\tLoss 0.2674 (0.5452)\tAccuracy 88.281 (82.159)\tTime 3.33\n",
      "Epoch: [27][199/573]\tLoss 0.2909 (0.5434)\tAccuracy 91.406 (82.220)\tTime 1.83\n",
      "Epoch: [27][299/573]\tLoss 0.1756 (0.5416)\tAccuracy 96.094 (82.282)\tTime 1.57\n",
      "Epoch: [27][399/573]\tLoss 0.2616 (0.5399)\tAccuracy 91.406 (82.345)\tTime 1.73\n",
      "Epoch: [27][499/573]\tLoss 0.1227 (0.5381)\tAccuracy 96.875 (82.408)\tTime 1.66\n",
      "train_accuracy 82.452\n",
      "Epoch: [28][99/573]\tLoss 0.1903 (0.5350)\tAccuracy 92.969 (82.512)\tTime 3.41\n",
      "Epoch: [28][199/573]\tLoss 0.2278 (0.5333)\tAccuracy 90.625 (82.570)\tTime 1.85\n",
      "Epoch: [28][299/573]\tLoss 0.1646 (0.5317)\tAccuracy 95.312 (82.629)\tTime 1.62\n",
      "Epoch: [28][399/573]\tLoss 0.1853 (0.5300)\tAccuracy 95.312 (82.689)\tTime 1.73\n",
      "Epoch: [28][499/573]\tLoss 0.2560 (0.5284)\tAccuracy 91.406 (82.746)\tTime 1.84\n",
      "train_accuracy 82.785\n",
      "Epoch: [29][99/573]\tLoss 0.2575 (0.5256)\tAccuracy 90.625 (82.843)\tTime 3.43\n",
      "Epoch: [29][199/573]\tLoss 0.2888 (0.5239)\tAccuracy 92.188 (82.900)\tTime 1.71\n",
      "Epoch: [29][299/573]\tLoss 0.3048 (0.5223)\tAccuracy 90.625 (82.955)\tTime 1.62\n",
      "Epoch: [29][399/573]\tLoss 0.1905 (0.5208)\tAccuracy 92.188 (83.009)\tTime 1.73\n",
      "Epoch: [29][499/573]\tLoss 0.1487 (0.5193)\tAccuracy 95.312 (83.062)\tTime 1.57\n",
      "train_accuracy 83.102\n",
      "Epoch: [30][99/573]\tLoss 0.1478 (0.5166)\tAccuracy 96.875 (83.158)\tTime 3.45\n",
      "Epoch: [30][199/573]\tLoss 0.2309 (0.5151)\tAccuracy 92.969 (83.209)\tTime 1.66\n",
      "Epoch: [30][299/573]\tLoss 0.3621 (0.5136)\tAccuracy 89.062 (83.262)\tTime 2.25\n",
      "Epoch: [30][399/573]\tLoss 0.1548 (0.5121)\tAccuracy 95.312 (83.312)\tTime 1.67\n",
      "Epoch: [30][499/573]\tLoss 0.4075 (0.5107)\tAccuracy 89.844 (83.362)\tTime 1.61\n",
      "train_accuracy 83.398\n",
      "Epoch: [31][99/573]\tLoss 0.2415 (0.5082)\tAccuracy 92.188 (83.449)\tTime 3.06\n",
      "Epoch: [31][199/573]\tLoss 0.2062 (0.5067)\tAccuracy 94.531 (83.502)\tTime 1.55\n",
      "Epoch: [31][299/573]\tLoss 0.2556 (0.5053)\tAccuracy 93.750 (83.551)\tTime 1.69\n",
      "Epoch: [31][399/573]\tLoss 0.2451 (0.5039)\tAccuracy 91.406 (83.600)\tTime 1.88\n",
      "Epoch: [31][499/573]\tLoss 0.1827 (0.5024)\tAccuracy 94.531 (83.650)\tTime 1.73\n",
      "train_accuracy 83.684\n",
      "Epoch: [32][99/573]\tLoss 0.3240 (0.5001)\tAccuracy 94.531 (83.735)\tTime 3.07\n",
      "Epoch: [32][199/573]\tLoss 0.2755 (0.4988)\tAccuracy 89.062 (83.780)\tTime 1.60\n",
      "Epoch: [32][299/573]\tLoss 0.1467 (0.4974)\tAccuracy 94.531 (83.827)\tTime 1.72\n",
      "Epoch: [32][399/573]\tLoss 0.2731 (0.4960)\tAccuracy 90.625 (83.874)\tTime 1.64\n",
      "Epoch: [32][499/573]\tLoss 0.4032 (0.4947)\tAccuracy 88.281 (83.920)\tTime 2.00\n",
      "train_accuracy 83.953\n",
      "Epoch: [33][99/573]\tLoss 0.3348 (0.4924)\tAccuracy 91.406 (83.999)\tTime 3.11\n",
      "Epoch: [33][199/573]\tLoss 0.3029 (0.4911)\tAccuracy 92.188 (84.045)\tTime 1.70\n",
      "Epoch: [33][299/573]\tLoss 0.3939 (0.4898)\tAccuracy 92.188 (84.090)\tTime 1.67\n",
      "Epoch: [33][399/573]\tLoss 0.1475 (0.4885)\tAccuracy 96.094 (84.136)\tTime 1.72\n",
      "Epoch: [33][499/573]\tLoss 0.2118 (0.4872)\tAccuracy 93.750 (84.180)\tTime 1.59\n",
      "train_accuracy 84.212\n",
      "Epoch: [34][99/573]\tLoss 0.1445 (0.4850)\tAccuracy 96.875 (84.259)\tTime 3.33\n",
      "Epoch: [34][199/573]\tLoss 0.1883 (0.4837)\tAccuracy 93.750 (84.301)\tTime 1.54\n",
      "Epoch: [34][299/573]\tLoss 0.3149 (0.4825)\tAccuracy 90.625 (84.343)\tTime 1.67\n",
      "Epoch: [34][399/573]\tLoss 0.1788 (0.4813)\tAccuracy 93.750 (84.384)\tTime 1.67\n",
      "Epoch: [34][499/573]\tLoss 0.2564 (0.4800)\tAccuracy 90.625 (84.428)\tTime 1.79\n",
      "train_accuracy 84.458\n",
      "Epoch: [35][99/573]\tLoss 0.1548 (0.4780)\tAccuracy 95.312 (84.499)\tTime 3.29\n",
      "Epoch: [35][199/573]\tLoss 0.2794 (0.4768)\tAccuracy 92.188 (84.542)\tTime 1.79\n",
      "Epoch: [35][299/573]\tLoss 0.2997 (0.4756)\tAccuracy 90.625 (84.583)\tTime 1.59\n",
      "Epoch: [35][399/573]\tLoss 0.1489 (0.4745)\tAccuracy 96.094 (84.625)\tTime 1.66\n",
      "Epoch: [35][499/573]\tLoss 0.1794 (0.4733)\tAccuracy 96.094 (84.665)\tTime 1.59\n",
      "train_accuracy 84.695\n",
      "Epoch: [36][99/573]\tLoss 0.1509 (0.4713)\tAccuracy 94.531 (84.734)\tTime 3.18\n",
      "Epoch: [36][199/573]\tLoss 0.1486 (0.4701)\tAccuracy 96.875 (84.775)\tTime 1.74\n",
      "Epoch: [36][299/573]\tLoss 0.1614 (0.4690)\tAccuracy 94.531 (84.813)\tTime 1.79\n",
      "Epoch: [36][399/573]\tLoss 0.1135 (0.4679)\tAccuracy 97.656 (84.853)\tTime 1.60\n",
      "Epoch: [36][499/573]\tLoss 0.2048 (0.4667)\tAccuracy 96.094 (84.892)\tTime 1.55\n",
      "train_accuracy 84.919\n",
      "Epoch: [37][99/573]\tLoss 0.2856 (0.4648)\tAccuracy 93.750 (84.958)\tTime 3.07\n",
      "Epoch: [37][199/573]\tLoss 0.3462 (0.4638)\tAccuracy 92.188 (84.996)\tTime 1.74\n",
      "Epoch: [37][299/573]\tLoss 0.1985 (0.4627)\tAccuracy 96.094 (85.035)\tTime 1.73\n",
      "Epoch: [37][399/573]\tLoss 0.1810 (0.4615)\tAccuracy 93.750 (85.073)\tTime 2.37\n",
      "Epoch: [37][499/573]\tLoss 0.2095 (0.4605)\tAccuracy 92.969 (85.109)\tTime 1.69\n",
      "train_accuracy 85.137\n",
      "Epoch: [38][99/573]\tLoss 0.2308 (0.4587)\tAccuracy 90.625 (85.173)\tTime 3.13\n",
      "Epoch: [38][199/573]\tLoss 0.1496 (0.4576)\tAccuracy 94.531 (85.211)\tTime 1.61\n",
      "Epoch: [38][299/573]\tLoss 0.1281 (0.4565)\tAccuracy 96.094 (85.248)\tTime 1.63\n",
      "Epoch: [38][399/573]\tLoss 0.1961 (0.4555)\tAccuracy 94.531 (85.285)\tTime 1.59\n",
      "Epoch: [38][499/573]\tLoss 0.2290 (0.4545)\tAccuracy 94.531 (85.320)\tTime 1.57\n",
      "train_accuracy 85.346\n",
      "Epoch: [39][99/573]\tLoss 0.1416 (0.4527)\tAccuracy 95.312 (85.382)\tTime 3.55\n",
      "Epoch: [39][199/573]\tLoss 0.1293 (0.4517)\tAccuracy 96.875 (85.417)\tTime 1.74\n",
      "Epoch: [39][299/573]\tLoss 0.1790 (0.4507)\tAccuracy 95.312 (85.452)\tTime 1.74\n",
      "Epoch: [39][399/573]\tLoss 0.2847 (0.4497)\tAccuracy 88.281 (85.487)\tTime 1.77\n",
      "Epoch: [39][499/573]\tLoss 0.2047 (0.4487)\tAccuracy 94.531 (85.521)\tTime 1.74\n",
      "train_accuracy 85.546\n",
      "Epoch: [40][99/573]\tLoss 0.1744 (0.4470)\tAccuracy 96.094 (85.580)\tTime 3.49\n",
      "Epoch: [40][199/573]\tLoss 0.1190 (0.4460)\tAccuracy 96.875 (85.615)\tTime 1.73\n",
      "Epoch: [40][299/573]\tLoss 0.3113 (0.4450)\tAccuracy 91.406 (85.648)\tTime 1.82\n",
      "Epoch: [40][399/573]\tLoss 0.2756 (0.4441)\tAccuracy 91.406 (85.682)\tTime 1.67\n",
      "Epoch: [40][499/573]\tLoss 0.2752 (0.4431)\tAccuracy 92.188 (85.714)\tTime 1.73\n",
      "train_accuracy 85.738\n",
      "Epoch: [41][99/573]\tLoss 0.0748 (0.4415)\tAccuracy 99.219 (85.771)\tTime 3.17\n",
      "Epoch: [41][199/573]\tLoss 0.2687 (0.4405)\tAccuracy 91.406 (85.804)\tTime 1.77\n",
      "Epoch: [41][299/573]\tLoss 0.2290 (0.4395)\tAccuracy 92.969 (85.837)\tTime 1.65\n",
      "Epoch: [41][399/573]\tLoss 0.1129 (0.4385)\tAccuracy 94.531 (85.870)\tTime 1.57\n",
      "Epoch: [41][499/573]\tLoss 0.4091 (0.4377)\tAccuracy 89.844 (85.901)\tTime 1.89\n",
      "train_accuracy 85.924\n",
      "Epoch: [42][99/573]\tLoss 0.1845 (0.4361)\tAccuracy 93.750 (85.956)\tTime 3.34\n",
      "Epoch: [42][199/573]\tLoss 0.2383 (0.4352)\tAccuracy 94.531 (85.988)\tTime 1.61\n",
      "Epoch: [42][299/573]\tLoss 0.2701 (0.4343)\tAccuracy 91.406 (86.019)\tTime 1.68\n",
      "Epoch: [42][399/573]\tLoss 0.2338 (0.4334)\tAccuracy 93.750 (86.049)\tTime 1.71\n",
      "Epoch: [42][499/573]\tLoss 0.1836 (0.4325)\tAccuracy 93.750 (86.081)\tTime 1.91\n",
      "train_accuracy 86.103\n",
      "Epoch: [43][99/573]\tLoss 0.1820 (0.4309)\tAccuracy 93.750 (86.134)\tTime 3.13\n",
      "Epoch: [43][199/573]\tLoss 0.1130 (0.4300)\tAccuracy 96.875 (86.164)\tTime 1.62\n",
      "Epoch: [43][299/573]\tLoss 0.2081 (0.4291)\tAccuracy 94.531 (86.195)\tTime 1.86\n",
      "Epoch: [43][399/573]\tLoss 0.1500 (0.4283)\tAccuracy 93.750 (86.225)\tTime 1.74\n",
      "Epoch: [43][499/573]\tLoss 0.1911 (0.4274)\tAccuracy 93.750 (86.254)\tTime 1.86\n",
      "train_accuracy 86.276\n",
      "Epoch: [44][99/573]\tLoss 0.2149 (0.4259)\tAccuracy 93.750 (86.306)\tTime 3.18\n",
      "Epoch: [44][199/573]\tLoss 0.1769 (0.4251)\tAccuracy 91.406 (86.335)\tTime 1.63\n",
      "Epoch: [44][299/573]\tLoss 0.1816 (0.4242)\tAccuracy 92.188 (86.365)\tTime 1.69\n",
      "Epoch: [44][399/573]\tLoss 0.1551 (0.4234)\tAccuracy 96.094 (86.391)\tTime 1.79\n",
      "Epoch: [44][499/573]\tLoss 0.2645 (0.4226)\tAccuracy 92.969 (86.420)\tTime 2.20\n",
      "train_accuracy 86.441\n",
      "Epoch: [45][99/573]\tLoss 0.2639 (0.4212)\tAccuracy 92.969 (86.469)\tTime 3.13\n",
      "Epoch: [45][199/573]\tLoss 0.4116 (0.4203)\tAccuracy 89.062 (86.498)\tTime 1.79\n",
      "Epoch: [45][299/573]\tLoss 0.2068 (0.4195)\tAccuracy 93.750 (86.526)\tTime 1.91\n",
      "Epoch: [45][399/573]\tLoss 0.0856 (0.4187)\tAccuracy 96.875 (86.555)\tTime 1.97\n",
      "Epoch: [45][499/573]\tLoss 0.1725 (0.4179)\tAccuracy 94.531 (86.581)\tTime 1.64\n",
      "train_accuracy 86.601\n",
      "Epoch: [46][99/573]\tLoss 0.1752 (0.4165)\tAccuracy 93.750 (86.630)\tTime 3.35\n",
      "Epoch: [46][199/573]\tLoss 0.1993 (0.4157)\tAccuracy 92.969 (86.657)\tTime 1.69\n",
      "Epoch: [46][299/573]\tLoss 0.1402 (0.4149)\tAccuracy 95.312 (86.683)\tTime 2.00\n",
      "Epoch: [46][399/573]\tLoss 0.2217 (0.4141)\tAccuracy 91.406 (86.711)\tTime 2.00\n",
      "Epoch: [46][499/573]\tLoss 0.4178 (0.4133)\tAccuracy 89.062 (86.738)\tTime 1.85\n",
      "train_accuracy 86.756\n",
      "Epoch: [47][99/573]\tLoss 0.2405 (0.4120)\tAccuracy 89.844 (86.783)\tTime 3.59\n",
      "Epoch: [47][199/573]\tLoss 0.1424 (0.4112)\tAccuracy 95.312 (86.809)\tTime 1.59\n",
      "Epoch: [47][299/573]\tLoss 0.0905 (0.4105)\tAccuracy 97.656 (86.836)\tTime 1.87\n",
      "Epoch: [47][399/573]\tLoss 0.2644 (0.4097)\tAccuracy 92.188 (86.863)\tTime 1.95\n",
      "Epoch: [47][499/573]\tLoss 0.1672 (0.4089)\tAccuracy 94.531 (86.889)\tTime 1.71\n",
      "train_accuracy 86.908\n",
      "Epoch: [48][99/573]\tLoss 0.2690 (0.4076)\tAccuracy 89.844 (86.934)\tTime 3.22\n",
      "Epoch: [48][199/573]\tLoss 0.1723 (0.4069)\tAccuracy 93.750 (86.960)\tTime 1.68\n",
      "Epoch: [48][299/573]\tLoss 0.2411 (0.4061)\tAccuracy 94.531 (86.984)\tTime 1.70\n",
      "Epoch: [48][399/573]\tLoss 0.3313 (0.4054)\tAccuracy 92.969 (87.009)\tTime 1.71\n",
      "Epoch: [48][499/573]\tLoss 0.2909 (0.4047)\tAccuracy 92.969 (87.035)\tTime 1.66\n",
      "train_accuracy 87.053\n",
      "Epoch: [49][99/573]\tLoss 0.1784 (0.4034)\tAccuracy 95.312 (87.079)\tTime 3.38\n",
      "Epoch: [49][199/573]\tLoss 0.2005 (0.4026)\tAccuracy 92.969 (87.105)\tTime 1.68\n",
      "Epoch: [49][299/573]\tLoss 0.1576 (0.4019)\tAccuracy 95.312 (87.129)\tTime 1.70\n",
      "Epoch: [49][399/573]\tLoss 0.1719 (0.4012)\tAccuracy 93.750 (87.153)\tTime 1.72\n",
      "Epoch: [49][499/573]\tLoss 0.1519 (0.4005)\tAccuracy 96.094 (87.177)\tTime 1.66\n",
      "train_accuracy 87.194\n",
      "Epoch: [50][99/573]\tLoss 0.1280 (0.3993)\tAccuracy 95.312 (87.219)\tTime 3.48\n",
      "Epoch: [50][199/573]\tLoss 0.1259 (0.3986)\tAccuracy 95.312 (87.242)\tTime 1.81\n",
      "Epoch: [50][299/573]\tLoss 0.1004 (0.3979)\tAccuracy 97.656 (87.267)\tTime 1.72\n",
      "Epoch: [50][399/573]\tLoss 0.2009 (0.3972)\tAccuracy 94.531 (87.290)\tTime 1.70\n",
      "Epoch: [50][499/573]\tLoss 0.2361 (0.3965)\tAccuracy 93.750 (87.315)\tTime 1.65\n",
      "train_accuracy 87.331\n",
      "Epoch: [51][99/573]\tLoss 0.2168 (0.3953)\tAccuracy 93.750 (87.355)\tTime 3.19\n",
      "Epoch: [51][199/573]\tLoss 0.2513 (0.3946)\tAccuracy 92.969 (87.378)\tTime 1.65\n",
      "Epoch: [51][299/573]\tLoss 0.1476 (0.3939)\tAccuracy 96.094 (87.402)\tTime 1.65\n",
      "Epoch: [51][399/573]\tLoss 0.0947 (0.3932)\tAccuracy 98.438 (87.425)\tTime 1.60\n",
      "Epoch: [51][499/573]\tLoss 0.1313 (0.3926)\tAccuracy 96.094 (87.448)\tTime 1.58\n",
      "train_accuracy 87.464\n",
      "Epoch: [52][99/573]\tLoss 0.1892 (0.3914)\tAccuracy 94.531 (87.488)\tTime 3.35\n",
      "Epoch: [52][199/573]\tLoss 0.1716 (0.3907)\tAccuracy 94.531 (87.511)\tTime 1.89\n",
      "Epoch: [52][299/573]\tLoss 0.3022 (0.3901)\tAccuracy 90.625 (87.533)\tTime 1.64\n",
      "Epoch: [52][399/573]\tLoss 0.1065 (0.3894)\tAccuracy 96.875 (87.555)\tTime 1.64\n",
      "Epoch: [52][499/573]\tLoss 0.1062 (0.3887)\tAccuracy 97.656 (87.579)\tTime 1.63\n",
      "train_accuracy 87.595\n",
      "Epoch: [53][99/573]\tLoss 0.1597 (0.3876)\tAccuracy 95.312 (87.618)\tTime 3.21\n",
      "Epoch: [53][199/573]\tLoss 0.1290 (0.3870)\tAccuracy 96.094 (87.639)\tTime 1.86\n",
      "Epoch: [53][299/573]\tLoss 0.1529 (0.3863)\tAccuracy 94.531 (87.662)\tTime 1.68\n",
      "Epoch: [53][399/573]\tLoss 0.0979 (0.3857)\tAccuracy 96.875 (87.683)\tTime 1.63\n",
      "Epoch: [53][499/573]\tLoss 0.1837 (0.3850)\tAccuracy 95.312 (87.704)\tTime 1.52\n",
      "train_accuracy 87.720\n",
      "Epoch: [54][99/573]\tLoss 0.1841 (0.3839)\tAccuracy 92.969 (87.741)\tTime 3.11\n",
      "Epoch: [54][199/573]\tLoss 0.2093 (0.3833)\tAccuracy 93.750 (87.763)\tTime 1.99\n",
      "Epoch: [54][299/573]\tLoss 0.1182 (0.3827)\tAccuracy 95.312 (87.784)\tTime 1.84\n",
      "Epoch: [54][399/573]\tLoss 0.2585 (0.3821)\tAccuracy 91.406 (87.805)\tTime 1.71\n",
      "Epoch: [54][499/573]\tLoss 0.1241 (0.3814)\tAccuracy 97.656 (87.827)\tTime 1.61\n",
      "train_accuracy 87.843\n",
      "Epoch: [55][99/573]\tLoss 0.1566 (0.3803)\tAccuracy 94.531 (87.865)\tTime 3.22\n",
      "Epoch: [55][199/573]\tLoss 0.1750 (0.3797)\tAccuracy 92.969 (87.886)\tTime 1.67\n",
      "Epoch: [55][299/573]\tLoss 0.1531 (0.3791)\tAccuracy 94.531 (87.908)\tTime 1.71\n",
      "Epoch: [55][399/573]\tLoss 0.1422 (0.3785)\tAccuracy 95.312 (87.927)\tTime 1.91\n",
      "Epoch: [55][499/573]\tLoss 0.1955 (0.3779)\tAccuracy 93.750 (87.948)\tTime 1.84\n",
      "train_accuracy 87.963\n",
      "Epoch: [56][99/573]\tLoss 0.0996 (0.3768)\tAccuracy 96.875 (87.984)\tTime 3.41\n",
      "Epoch: [56][199/573]\tLoss 0.2778 (0.3762)\tAccuracy 90.625 (88.004)\tTime 1.53\n",
      "Epoch: [56][299/573]\tLoss 0.1712 (0.3756)\tAccuracy 93.750 (88.024)\tTime 1.53\n",
      "Epoch: [56][399/573]\tLoss 0.1092 (0.3750)\tAccuracy 98.438 (88.045)\tTime 1.66\n",
      "Epoch: [56][499/573]\tLoss 0.1369 (0.3744)\tAccuracy 95.312 (88.065)\tTime 1.85\n",
      "train_accuracy 88.080\n",
      "Epoch: [57][99/573]\tLoss 0.2354 (0.3734)\tAccuracy 93.750 (88.100)\tTime 3.31\n",
      "Epoch: [57][199/573]\tLoss 0.1174 (0.3728)\tAccuracy 95.312 (88.119)\tTime 1.63\n",
      "Epoch: [57][299/573]\tLoss 0.1981 (0.3722)\tAccuracy 92.969 (88.140)\tTime 1.74\n",
      "Epoch: [57][399/573]\tLoss 0.3076 (0.3716)\tAccuracy 93.750 (88.160)\tTime 1.94\n",
      "Epoch: [57][499/573]\tLoss 0.2152 (0.3711)\tAccuracy 93.750 (88.179)\tTime 2.03\n",
      "train_accuracy 88.192\n",
      "Epoch: [58][99/573]\tLoss 0.1509 (0.3701)\tAccuracy 93.750 (88.213)\tTime 3.56\n",
      "Epoch: [58][199/573]\tLoss 0.1281 (0.3695)\tAccuracy 96.094 (88.231)\tTime 1.73\n",
      "Epoch: [58][299/573]\tLoss 0.1963 (0.3690)\tAccuracy 93.750 (88.251)\tTime 1.68\n",
      "Epoch: [58][399/573]\tLoss 0.1446 (0.3684)\tAccuracy 97.656 (88.269)\tTime 1.57\n",
      "Epoch: [58][499/573]\tLoss 0.1007 (0.3678)\tAccuracy 97.656 (88.289)\tTime 1.58\n",
      "train_accuracy 88.303\n",
      "Epoch: [59][99/573]\tLoss 0.1798 (0.3668)\tAccuracy 93.750 (88.323)\tTime 3.30\n",
      "Epoch: [59][199/573]\tLoss 0.1288 (0.3662)\tAccuracy 95.312 (88.342)\tTime 2.12\n",
      "Epoch: [59][299/573]\tLoss 0.2029 (0.3657)\tAccuracy 95.312 (88.360)\tTime 1.58\n",
      "Epoch: [59][399/573]\tLoss 0.2836 (0.3652)\tAccuracy 91.406 (88.378)\tTime 1.64\n",
      "Epoch: [59][499/573]\tLoss 0.1486 (0.3646)\tAccuracy 95.312 (88.397)\tTime 1.56\n",
      "train_accuracy 88.409\n",
      "Epoch: [60][99/573]\tLoss 0.1716 (0.3637)\tAccuracy 96.094 (88.427)\tTime 3.47\n",
      "Epoch: [60][199/573]\tLoss 0.2212 (0.3632)\tAccuracy 93.750 (88.447)\tTime 1.86\n",
      "Epoch: [60][299/573]\tLoss 0.2068 (0.3626)\tAccuracy 94.531 (88.465)\tTime 1.66\n",
      "Epoch: [60][399/573]\tLoss 0.1382 (0.3621)\tAccuracy 96.875 (88.483)\tTime 1.65\n",
      "Epoch: [60][499/573]\tLoss 0.0995 (0.3615)\tAccuracy 97.656 (88.501)\tTime 1.55\n",
      "train_accuracy 88.514\n",
      "Epoch: [61][99/573]\tLoss 0.2454 (0.3606)\tAccuracy 92.188 (88.533)\tTime 3.24\n",
      "Epoch: [61][199/573]\tLoss 0.1800 (0.3601)\tAccuracy 93.750 (88.550)\tTime 1.68\n",
      "Epoch: [61][299/573]\tLoss 0.2401 (0.3595)\tAccuracy 93.750 (88.568)\tTime 1.63\n",
      "Epoch: [61][399/573]\tLoss 0.1543 (0.3590)\tAccuracy 95.312 (88.586)\tTime 1.84\n",
      "Epoch: [61][499/573]\tLoss 0.1764 (0.3585)\tAccuracy 94.531 (88.603)\tTime 1.80\n",
      "train_accuracy 88.616\n",
      "Epoch: [62][99/573]\tLoss 0.0994 (0.3576)\tAccuracy 96.875 (88.632)\tTime 3.35\n",
      "Epoch: [62][199/573]\tLoss 0.1862 (0.3571)\tAccuracy 93.750 (88.651)\tTime 2.01\n",
      "Epoch: [62][299/573]\tLoss 0.1068 (0.3565)\tAccuracy 97.656 (88.668)\tTime 1.57\n",
      "Epoch: [62][399/573]\tLoss 0.1104 (0.3560)\tAccuracy 96.875 (88.685)\tTime 1.59\n",
      "Epoch: [62][499/573]\tLoss 0.1525 (0.3556)\tAccuracy 95.312 (88.702)\tTime 1.85\n",
      "train_accuracy 88.715\n",
      "Epoch: [63][99/573]\tLoss 0.1442 (0.3547)\tAccuracy 96.094 (88.732)\tTime 3.40\n",
      "Epoch: [63][199/573]\tLoss 0.1558 (0.3542)\tAccuracy 96.094 (88.749)\tTime 1.79\n",
      "Epoch: [63][299/573]\tLoss 0.1504 (0.3537)\tAccuracy 92.969 (88.766)\tTime 1.94\n",
      "Epoch: [63][399/573]\tLoss 0.1269 (0.3531)\tAccuracy 96.094 (88.783)\tTime 1.77\n",
      "Epoch: [63][499/573]\tLoss 0.1216 (0.3526)\tAccuracy 95.312 (88.801)\tTime 1.91\n",
      "train_accuracy 88.812\n",
      "Epoch: [64][99/573]\tLoss 0.1557 (0.3518)\tAccuracy 94.531 (88.830)\tTime 3.40\n",
      "Epoch: [64][199/573]\tLoss 0.1513 (0.3513)\tAccuracy 96.094 (88.846)\tTime 1.61\n",
      "Epoch: [64][299/573]\tLoss 0.1369 (0.3508)\tAccuracy 97.656 (88.863)\tTime 1.64\n",
      "Epoch: [64][399/573]\tLoss 0.1703 (0.3503)\tAccuracy 94.531 (88.880)\tTime 1.57\n",
      "Epoch: [64][499/573]\tLoss 0.1292 (0.3498)\tAccuracy 96.094 (88.896)\tTime 1.59\n",
      "train_accuracy 88.908\n",
      "Epoch: [65][99/573]\tLoss 0.1901 (0.3489)\tAccuracy 92.969 (88.925)\tTime 3.33\n",
      "Epoch: [65][199/573]\tLoss 0.2985 (0.3484)\tAccuracy 90.625 (88.941)\tTime 1.64\n",
      "Epoch: [65][299/573]\tLoss 0.4035 (0.3479)\tAccuracy 90.625 (88.958)\tTime 1.51\n",
      "Epoch: [65][399/573]\tLoss 0.0780 (0.3474)\tAccuracy 97.656 (88.975)\tTime 1.52\n",
      "Epoch: [65][499/573]\tLoss 0.0918 (0.3470)\tAccuracy 96.875 (88.991)\tTime 1.57\n",
      "train_accuracy 89.002\n",
      "Epoch: [66][99/573]\tLoss 0.1947 (0.3461)\tAccuracy 94.531 (89.019)\tTime 3.04\n",
      "Epoch: [66][199/573]\tLoss 0.1746 (0.3456)\tAccuracy 96.094 (89.035)\tTime 1.88\n",
      "Epoch: [66][299/573]\tLoss 0.1415 (0.3452)\tAccuracy 95.312 (89.051)\tTime 2.10\n",
      "Epoch: [66][399/573]\tLoss 0.1744 (0.3447)\tAccuracy 96.094 (89.068)\tTime 1.76\n",
      "Epoch: [66][499/573]\tLoss 0.1618 (0.3442)\tAccuracy 95.312 (89.083)\tTime 1.97\n",
      "train_accuracy 89.094\n",
      "Epoch: [67][99/573]\tLoss 0.2634 (0.3434)\tAccuracy 94.531 (89.111)\tTime 3.36\n",
      "Epoch: [67][199/573]\tLoss 0.2788 (0.3429)\tAccuracy 92.188 (89.127)\tTime 1.66\n",
      "Epoch: [67][299/573]\tLoss 0.1827 (0.3425)\tAccuracy 93.750 (89.142)\tTime 1.68\n",
      "Epoch: [67][399/573]\tLoss 0.1582 (0.3420)\tAccuracy 94.531 (89.157)\tTime 1.96\n",
      "Epoch: [67][499/573]\tLoss 0.1938 (0.3416)\tAccuracy 94.531 (89.173)\tTime 1.85\n",
      "train_accuracy 89.184\n",
      "Epoch: [68][99/573]\tLoss 0.1248 (0.3407)\tAccuracy 93.750 (89.200)\tTime 3.38\n",
      "Epoch: [68][199/573]\tLoss 0.1438 (0.3403)\tAccuracy 96.875 (89.216)\tTime 1.63\n",
      "Epoch: [68][299/573]\tLoss 0.1522 (0.3398)\tAccuracy 95.312 (89.232)\tTime 1.68\n",
      "Epoch: [68][399/573]\tLoss 0.1948 (0.3393)\tAccuracy 96.094 (89.247)\tTime 1.64\n",
      "Epoch: [68][499/573]\tLoss 0.1764 (0.3389)\tAccuracy 94.531 (89.262)\tTime 1.89\n",
      "train_accuracy 89.272\n",
      "Epoch: [69][99/573]\tLoss 0.3085 (0.3382)\tAccuracy 94.531 (89.287)\tTime 3.20\n",
      "Epoch: [69][199/573]\tLoss 0.1676 (0.3377)\tAccuracy 94.531 (89.302)\tTime 1.69\n",
      "Epoch: [69][299/573]\tLoss 0.1409 (0.3373)\tAccuracy 94.531 (89.317)\tTime 1.79\n",
      "Epoch: [69][399/573]\tLoss 0.0805 (0.3368)\tAccuracy 97.656 (89.333)\tTime 1.76\n",
      "Epoch: [69][499/573]\tLoss 0.0372 (0.3363)\tAccuracy 99.219 (89.348)\tTime 1.68\n",
      "train_accuracy 89.358\n",
      "Epoch: [70][99/573]\tLoss 0.1901 (0.3356)\tAccuracy 94.531 (89.372)\tTime 3.69\n",
      "Epoch: [70][199/573]\tLoss 0.1862 (0.3352)\tAccuracy 94.531 (89.388)\tTime 1.70\n",
      "Epoch: [70][299/573]\tLoss 0.2176 (0.3347)\tAccuracy 94.531 (89.403)\tTime 1.92\n",
      "Epoch: [70][399/573]\tLoss 0.1417 (0.3343)\tAccuracy 96.875 (89.417)\tTime 1.60\n",
      "Epoch: [70][499/573]\tLoss 0.1387 (0.3339)\tAccuracy 95.312 (89.431)\tTime 1.59\n",
      "train_accuracy 89.443\n",
      "Epoch: [71][99/573]\tLoss 0.1145 (0.3331)\tAccuracy 96.094 (89.458)\tTime 3.33\n",
      "Epoch: [71][199/573]\tLoss 0.0676 (0.3326)\tAccuracy 96.875 (89.473)\tTime 1.78\n",
      "Epoch: [71][299/573]\tLoss 0.1584 (0.3322)\tAccuracy 96.094 (89.487)\tTime 1.93\n",
      "Epoch: [71][399/573]\tLoss 0.1199 (0.3318)\tAccuracy 94.531 (89.501)\tTime 1.71\n",
      "Epoch: [71][499/573]\tLoss 0.2374 (0.3314)\tAccuracy 93.750 (89.515)\tTime 1.81\n",
      "train_accuracy 89.526\n",
      "Epoch: [72][99/573]\tLoss 0.1268 (0.3306)\tAccuracy 96.094 (89.541)\tTime 3.37\n",
      "Epoch: [72][199/573]\tLoss 0.1037 (0.3302)\tAccuracy 96.094 (89.555)\tTime 1.73\n",
      "Epoch: [72][299/573]\tLoss 0.1223 (0.3298)\tAccuracy 96.875 (89.568)\tTime 1.90\n",
      "Epoch: [72][399/573]\tLoss 0.1746 (0.3294)\tAccuracy 94.531 (89.582)\tTime 1.65\n",
      "Epoch: [72][499/573]\tLoss 0.1908 (0.3289)\tAccuracy 94.531 (89.597)\tTime 1.69\n",
      "train_accuracy 89.607\n",
      "Epoch: [73][99/573]\tLoss 0.0905 (0.3282)\tAccuracy 97.656 (89.621)\tTime 3.25\n",
      "Epoch: [73][199/573]\tLoss 0.1148 (0.3278)\tAccuracy 95.312 (89.635)\tTime 1.61\n",
      "Epoch: [73][299/573]\tLoss 0.2098 (0.3274)\tAccuracy 94.531 (89.648)\tTime 1.63\n",
      "Epoch: [73][399/573]\tLoss 0.0559 (0.3270)\tAccuracy 97.656 (89.661)\tTime 1.94\n",
      "Epoch: [73][499/573]\tLoss 0.2186 (0.3266)\tAccuracy 93.750 (89.675)\tTime 1.96\n",
      "train_accuracy 89.685\n",
      "Epoch: [74][99/573]\tLoss 0.1720 (0.3259)\tAccuracy 95.312 (89.699)\tTime 3.62\n",
      "Epoch: [74][199/573]\tLoss 0.1591 (0.3254)\tAccuracy 95.312 (89.712)\tTime 1.93\n",
      "Epoch: [74][299/573]\tLoss 0.0938 (0.3250)\tAccuracy 97.656 (89.726)\tTime 1.75\n",
      "Epoch: [74][399/573]\tLoss 0.1804 (0.3246)\tAccuracy 95.312 (89.739)\tTime 1.90\n",
      "Epoch: [74][499/573]\tLoss 0.0990 (0.3242)\tAccuracy 94.531 (89.752)\tTime 1.75\n",
      "train_accuracy 89.762\n",
      "Epoch: [75][99/573]\tLoss 0.1560 (0.3236)\tAccuracy 95.312 (89.775)\tTime 3.14\n",
      "Epoch: [75][199/573]\tLoss 0.1946 (0.3232)\tAccuracy 94.531 (89.788)\tTime 1.60\n",
      "Epoch: [75][299/573]\tLoss 0.1604 (0.3228)\tAccuracy 96.094 (89.801)\tTime 1.58\n",
      "Epoch: [75][399/573]\tLoss 0.1298 (0.3224)\tAccuracy 96.875 (89.814)\tTime 1.69\n",
      "Epoch: [75][499/573]\tLoss 0.1557 (0.3220)\tAccuracy 92.969 (89.827)\tTime 1.65\n",
      "train_accuracy 89.837\n",
      "Epoch: [76][99/573]\tLoss 0.1455 (0.3212)\tAccuracy 95.312 (89.851)\tTime 3.23\n",
      "Epoch: [76][199/573]\tLoss 0.2670 (0.3208)\tAccuracy 93.750 (89.865)\tTime 1.82\n",
      "Epoch: [76][299/573]\tLoss 0.1250 (0.3205)\tAccuracy 97.656 (89.878)\tTime 1.89\n",
      "Epoch: [76][399/573]\tLoss 0.1212 (0.3201)\tAccuracy 96.875 (89.891)\tTime 1.96\n",
      "Epoch: [76][499/573]\tLoss 0.1696 (0.3197)\tAccuracy 94.531 (89.903)\tTime 1.79\n",
      "train_accuracy 89.912\n",
      "Epoch: [77][99/573]\tLoss 0.1559 (0.3190)\tAccuracy 96.875 (89.926)\tTime 3.52\n",
      "Epoch: [77][199/573]\tLoss 0.2332 (0.3186)\tAccuracy 94.531 (89.939)\tTime 1.93\n",
      "Epoch: [77][299/573]\tLoss 0.1300 (0.3182)\tAccuracy 95.312 (89.952)\tTime 2.07\n",
      "Epoch: [77][399/573]\tLoss 0.2356 (0.3179)\tAccuracy 94.531 (89.964)\tTime 1.67\n",
      "Epoch: [77][499/573]\tLoss 0.0558 (0.3175)\tAccuracy 98.438 (89.977)\tTime 1.91\n",
      "train_accuracy 89.986\n",
      "Epoch: [78][99/573]\tLoss 0.1790 (0.3168)\tAccuracy 94.531 (89.998)\tTime 3.15\n",
      "Epoch: [78][199/573]\tLoss 0.0877 (0.3164)\tAccuracy 97.656 (90.012)\tTime 1.67\n",
      "Epoch: [78][299/573]\tLoss 0.1058 (0.3161)\tAccuracy 98.438 (90.024)\tTime 1.72\n",
      "Epoch: [78][399/573]\tLoss 0.0939 (0.3157)\tAccuracy 95.312 (90.036)\tTime 1.65\n",
      "Epoch: [78][499/573]\tLoss 0.1941 (0.3153)\tAccuracy 95.312 (90.048)\tTime 1.74\n",
      "train_accuracy 90.058\n",
      "Epoch: [79][99/573]\tLoss 0.2036 (0.3147)\tAccuracy 93.750 (90.070)\tTime 3.25\n",
      "Epoch: [79][199/573]\tLoss 0.2045 (0.3143)\tAccuracy 92.969 (90.083)\tTime 1.81\n",
      "Epoch: [79][299/573]\tLoss 0.0988 (0.3139)\tAccuracy 94.531 (90.095)\tTime 1.79\n",
      "Epoch: [79][399/573]\tLoss 0.0521 (0.3135)\tAccuracy 98.438 (90.108)\tTime 1.80\n",
      "Epoch: [79][499/573]\tLoss 0.1737 (0.3131)\tAccuracy 92.969 (90.120)\tTime 1.80\n",
      "train_accuracy 90.129\n",
      "Epoch: [80][99/573]\tLoss 0.1317 (0.3125)\tAccuracy 96.094 (90.141)\tTime 3.41\n",
      "Epoch: [80][199/573]\tLoss 0.1768 (0.3122)\tAccuracy 96.875 (90.153)\tTime 1.63\n",
      "Epoch: [80][299/573]\tLoss 0.1291 (0.3118)\tAccuracy 96.875 (90.165)\tTime 1.69\n",
      "Epoch: [80][399/573]\tLoss 0.2652 (0.3114)\tAccuracy 92.188 (90.178)\tTime 1.68\n",
      "Epoch: [80][499/573]\tLoss 0.0870 (0.3110)\tAccuracy 96.875 (90.189)\tTime 1.88\n",
      "train_accuracy 90.198\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bucsc-real.soe.ucsc.edu/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train(trainloader, model_ft, criterion, \u001b[39m100\u001b[39;49m)\n",
      "\u001b[1;32m/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb Cell 11\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bucsc-real.soe.ucsc.edu/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bucsc-real.soe.ucsc.edu/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bucsc-real.soe.ucsc.edu/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bucsc-real.soe.ucsc.edu/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m output \u001b[39m=\u001b[39m output_clean\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bucsc-real.soe.ucsc.edu/data1/zonglin/SG-Unlearn/src/train_purchase100.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/.conda/envs/SG/lib/python3.8/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.conda/envs/SG/lib/python3.8/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/.conda/envs/SG/lib/python3.8/site-packages/torch/optim/sgd.py:151\u001b[0m, in \u001b[0;36mSGD.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m             momentum_buffer_list\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmomentum_buffer\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 151\u001b[0m sgd(params_with_grad,\n\u001b[1;32m    152\u001b[0m     d_p_list,\n\u001b[1;32m    153\u001b[0m     momentum_buffer_list,\n\u001b[1;32m    154\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m     momentum\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmomentum\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m     lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m     dampening\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdampening\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m     nesterov\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mnesterov\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m     maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    160\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    161\u001b[0m     foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    163\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[0;32m~/.conda/envs/SG/lib/python3.8/site-packages/torch/optim/sgd.py:202\u001b[0m, in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[0;32m--> 202\u001b[0m func(params,\n\u001b[1;32m    203\u001b[0m      d_p_list,\n\u001b[1;32m    204\u001b[0m      momentum_buffer_list,\n\u001b[1;32m    205\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    206\u001b[0m      momentum\u001b[39m=\u001b[39;49mmomentum,\n\u001b[1;32m    207\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    208\u001b[0m      dampening\u001b[39m=\u001b[39;49mdampening,\n\u001b[1;32m    209\u001b[0m      nesterov\u001b[39m=\u001b[39;49mnesterov,\n\u001b[1;32m    210\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39;49mhas_sparse_grad,\n\u001b[1;32m    211\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
      "File \u001b[0;32m~/.conda/envs/SG/lib/python3.8/site-packages/torch/optim/sgd.py:245\u001b[0m, in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m         d_p \u001b[39m=\u001b[39m buf\n\u001b[0;32m--> 245\u001b[0m param\u001b[39m.\u001b[39;49madd_(d_p, alpha\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mlr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(trainloader, model_ft, criterion, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), \"svhn_ckpt.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
