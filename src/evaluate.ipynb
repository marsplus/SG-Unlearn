{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206f7371-80b9-4f39-8951-507d8b2ac406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:28:19.490046Z",
     "iopub.status.busy": "2023-09-22T20:28:19.489620Z",
     "iopub.status.idle": "2023-09-22T20:28:19.611707Z",
     "shell.execute_reply": "2023-09-22T20:28:19.610712Z",
     "shell.execute_reply.started": "2023-09-22T20:28:19.490016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import norm, ks_2samp, ttest_ind\n",
    "from scipy.special import kl_div, logit\n",
    "\n",
    "## to zip two lists of different lengths\n",
    "from itertools import zip_longest\n",
    "from utils import simple_mia\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from sklearn.metrics import roc_curve, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from models import DefenderOPT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5, 3)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044b2bf5-b81f-488c-a771-edfc42379585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:28:03.123697Z",
     "iopub.status.busy": "2023-09-22T20:28:03.122997Z",
     "iopub.status.idle": "2023-09-22T20:28:03.174705Z",
     "shell.execute_reply": "2023-09-22T20:28:03.174000Z",
     "shell.execute_reply.started": "2023-09-22T20:28:03.123664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### some auxiliary functions\n",
    "\n",
    "def compute_losses(net, loader, device):\n",
    "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    all_losses = []\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        logits = net(inputs)\n",
    "        losses = criterion(logits, targets).detach().cpu().numpy()\n",
    "        for l in losses:\n",
    "            all_losses.append(l)\n",
    "\n",
    "    return np.array(all_losses)\n",
    "\n",
    "\n",
    "# Define custom scoring function\n",
    "def custom_tpr_at_fpr(y_true, y_prob, desired_fprs=[0.01, 0.05, 0.1]):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    tprs_at_desired_fprs = np.interp(desired_fprs, fpr, tpr)\n",
    "    return np.array(tprs_at_desired_fprs)\n",
    "\n",
    "# Custom scorer using the custom scoring function\n",
    "def custom_scorer(clf, X, y):\n",
    "    y_prob = clf.predict_proba(X)[:, 1]  # probabilities for the positive class\n",
    "    return custom_tpr_at_fpr(y, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327f4ee-fc24-421a-a3d4-d3a07d487ed5",
   "metadata": {},
   "source": [
    "## Compare SG against the baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f533135c-6c6b-41ca-b883-e1f8f0dbfb0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:31:52.374042Z",
     "iopub.status.busy": "2023-09-22T20:31:52.373543Z",
     "iopub.status.idle": "2023-09-22T20:33:57.547674Z",
     "shell.execute_reply": "2023-09-22T20:33:57.546343Z",
     "shell.execute_reply.started": "2023-09-22T20:31:52.374001Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = 'cifar10'\n",
    "batch_size = 128\n",
    "device_id = 2\n",
    "device = f'cuda:{device_id}'\n",
    "num_classes = 10 if dataset == 'cifar10' else 100\n",
    "## 'GA', 'fisher_new', 'wfisher', 'IU', 'FT', 'retrainâ€™\n",
    "baseline = 'fisher_new'\n",
    "num_epoch = 30\n",
    "\n",
    "\n",
    "tprs_ret = np.zeros(3)\n",
    "acc_ret = []\n",
    "for seed in range(1, 11):\n",
    "    RNG = torch.Generator().manual_seed(seed)\n",
    "    SG_data = torch.load(f'../result/SG_data/SGdata_seed_{seed}_{dataset}.pth')\n",
    "    # SG_data = torch.load(f'SGdata_seed_{seed}_{dataset}.pth')\n",
    "    \n",
    "    \n",
    "    retain_dataset = SG_data['retain']\n",
    "    test_dataset = SG_data['test']\n",
    "    val_dataset = SG_data['val']\n",
    "    forget_dataset = SG_data['forget']\n",
    "    \n",
    "    retain_loader = torch.utils.data.DataLoader(\n",
    "        retain_dataset, batch_size=batch_size, shuffle=True, num_workers=2, generator=RNG)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, generator=RNG)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, generator=RNG)\n",
    "    forget_loader = torch.utils.data.DataLoader(\n",
    "        forget_dataset, batch_size=batch_size, shuffle=True, num_workers=2, generator=RNG)\n",
    "\n",
    "    evaluator = DefenderOPT(retain_loader, \n",
    "                            forget_loader, \n",
    "                            val_loader, \n",
    "                            test_loader,\n",
    "                            baseline_mode=1,\n",
    "                            cv=3,\n",
    "                            dim=1,\n",
    "                            seed=seed,\n",
    "                            device_id=device_id,\n",
    "                            num_class=num_classes)\n",
    "    \n",
    "    if baseline == 'SG':\n",
    "        try:\n",
    "            model_path = f\"../result/SG_data/SGcheckpoint_num_epoch_{num_epoch}_cv_3_dim_11_seed_{seed}_cifar10.pth\"\n",
    "            weights = torch.load(model_path, map_location=device)\n",
    "        except:\n",
    "            continue\n",
    "    elif baseline in ['GA', 'fisher_new', 'wfisher', 'IU', 'FT', 'retrain']:\n",
    "        model_path = f\"../result/baselines/{baseline}checkpoint_{seed}.pth.tar\"\n",
    "        weights = torch.load(model_path, map_location=device)['state_dict']\n",
    "    else:\n",
    "        raise ValueError(\"Unknown baselines.\")\n",
    "        \n",
    "    model = resnet18(num_classes=num_classes)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False)\n",
    "    model.load_state_dict(weights)\n",
    "    model.to(device)\n",
    "    \n",
    "    retain_acc = DefenderOPT._evaluate_accuracy(model, retain_loader, device=device)\n",
    "    test_acc = DefenderOPT._evaluate_accuracy(model, test_loader, device=device)\n",
    "    val_acc = DefenderOPT._evaluate_accuracy(model, val_loader, device=device)\n",
    "    forget_acc = DefenderOPT._evaluate_accuracy(model, forget_loader, device=device)\n",
    "    MIA_acc, MIA_recall, MIA_auc = DefenderOPT._evaluate_MIA(model, \n",
    "                                                             forget_loader, \n",
    "                                                             val_loader, \n",
    "                                                             dim=evaluator.dim,\n",
    "                                                             seed=seed,\n",
    "                                                             device=device,\n",
    "                                                             save=False)\n",
    "    acc_ret.append([retain_acc*100, test_acc*100, val_acc*100, forget_acc*100, MIA_acc*100, MIA_auc])\n",
    "\n",
    "    forget_losses = compute_losses(model, forget_loader, device)\n",
    "    val_losses = compute_losses(model, val_loader, device)\n",
    "\n",
    "    ## Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
    "    np.random.shuffle(forget_losses)\n",
    "    forget_losses = forget_losses[: len(val_losses)]\n",
    " \n",
    "    samples_mia = np.concatenate((val_losses, forget_losses)).reshape((-1, 1))\n",
    "    labels_mia = [0] * len(val_losses) + [1] * len(forget_losses)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(samples_mia, labels_mia, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    ## Get predicted probabilities\n",
    "    y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "    ## Compute the true positive rates at different false positive rates, e.g., the TPR when FPR=1%, the TPR when FPR=5%, etc. \n",
    "    ## This metric is suggested by Carlini, et al. in https://arxiv.org/abs/2112.03570\n",
    "    tprs_ret += custom_tpr_at_fpr(y_test, y_prob)\n",
    "    \n",
    "tprs_ret /= len(acc_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fed708d-6891-4ee5-8c0c-a2883bb4ece4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:33:57.550290Z",
     "iopub.status.busy": "2023-09-22T20:33:57.549895Z",
     "iopub.status.idle": "2023-09-22T20:33:57.784935Z",
     "shell.execute_reply": "2023-09-22T20:33:57.783997Z",
     "shell.execute_reply.started": "2023-09-22T20:33:57.550252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average acc. (%)\n",
      "RA          9.983556\n",
      "TA          9.930000\n",
      "VA          9.984000\n",
      "FA          9.926000\n",
      "MIA_acc    49.910000\n",
      "MIA_auc     0.495163\n",
      "dtype: float64\n",
      "\n",
      "95% confidence\n",
      "RA         0.516685\n",
      "TA         0.495130\n",
      "VA         0.508151\n",
      "FA         0.474270\n",
      "MIA_acc    0.180135\n",
      "MIA_auc    0.006538\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### get the accuracy on different subsets\n",
    "### RA: the accuracy on the retain set\n",
    "### TA: the accuracy on the test set\n",
    "### VA: the accuracy on the validation set\n",
    "### FA: the accuracy on the forget set\n",
    "### MIA_acc: the accuracy of the MIA \n",
    "### MIA_auc: the auc of the MIA\n",
    "\n",
    "acc_df = pd.DataFrame(acc_ret)\n",
    "acc_df.columns = ['RA', 'TA', 'VA', 'FA', 'MIA_acc', 'MIA_auc']\n",
    "\n",
    "print('Average acc. (%)')\n",
    "print(acc_df.mean())\n",
    "\n",
    "print()\n",
    "\n",
    "print('95% confidence')\n",
    "print(acc_df.sem() * 1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7be9c3a-7c39-4bb4-9d8d-170b5b892120",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:33:57.786397Z",
     "iopub.status.busy": "2023-09-22T20:33:57.786130Z",
     "iopub.status.idle": "2023-09-22T20:33:57.888481Z",
     "shell.execute_reply": "2023-09-22T20:33:57.887723Z",
     "shell.execute_reply.started": "2023-09-22T20:33:57.786372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.07943301 5.02136651 9.86753757]\n"
     ]
    }
   ],
   "source": [
    "## true positives at various false positive rates (1%, 5%, 10%)\n",
    "print(tprs_ret * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d53d43-9eb9-4642-893c-206d7aa6a666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
