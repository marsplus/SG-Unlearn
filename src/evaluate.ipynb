{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206f7371-80b9-4f39-8951-507d8b2ac406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:28:19.490046Z",
     "iopub.status.busy": "2023-09-22T20:28:19.489620Z",
     "iopub.status.idle": "2023-09-22T20:28:19.611707Z",
     "shell.execute_reply": "2023-09-22T20:28:19.610712Z",
     "shell.execute_reply.started": "2023-09-22T20:28:19.490016Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import norm, ks_2samp, ttest_ind\n",
    "from scipy.special import kl_div, logit\n",
    "\n",
    "## to zip two lists of different lengths\n",
    "from itertools import zip_longest\n",
    "from utils import simple_mia\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from sklearn.metrics import roc_curve, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from models import DefenderOPT\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5, 3)\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044b2bf5-b81f-488c-a771-edfc42379585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:28:03.123697Z",
     "iopub.status.busy": "2023-09-22T20:28:03.122997Z",
     "iopub.status.idle": "2023-09-22T20:28:03.174705Z",
     "shell.execute_reply": "2023-09-22T20:28:03.174000Z",
     "shell.execute_reply.started": "2023-09-22T20:28:03.123664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### some auxiliary functions\n",
    "\n",
    "def compute_losses(net, loader, device):\n",
    "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    all_losses = []\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        logits = net(inputs)\n",
    "        losses = criterion(logits, targets).detach().cpu().numpy()\n",
    "        for l in losses:\n",
    "            all_losses.append(l)\n",
    "\n",
    "    return np.array(all_losses)\n",
    "\n",
    "# Define custom scoring function\n",
    "def custom_tpr_at_fpr(y_true, y_prob, desired_fprs=[0.01, 0.05, 0.1]):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    tprs_at_desired_fprs = np.interp(desired_fprs, fpr, tpr)\n",
    "    return np.array(tprs_at_desired_fprs)\n",
    "\n",
    "# Custom scorer using the custom scoring function\n",
    "def custom_scorer(clf, X, y):\n",
    "    y_prob = clf.predict_proba(X)[:, 1]  # probabilities for the positive class\n",
    "    return custom_tpr_at_fpr(y, y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327f4ee-fc24-421a-a3d4-d3a07d487ed5",
   "metadata": {},
   "source": [
    "## Compare SG against the baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f533135c-6c6b-41ca-b883-e1f8f0dbfb0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-22T20:31:52.374042Z",
     "iopub.status.busy": "2023-09-22T20:31:52.373543Z",
     "iopub.status.idle": "2023-09-22T20:33:57.547674Z",
     "shell.execute_reply": "2023-09-22T20:33:57.546343Z",
     "shell.execute_reply.started": "2023-09-22T20:31:52.374001Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data1/zonglin/SG-Unlearn/result/baselines_SG_cifar100/\n"
     ]
    }
   ],
   "source": [
    "from models import DefenderOPT\n",
    "\n",
    "dataset = 'cifar100'\n",
    "batch_size = 128\n",
    "device_id = 2\n",
    "device = f'cuda:{device_id}'\n",
    "num_classes = 10 if dataset == 'cifar10' else 100\n",
    "baseline = 'FT'\n",
    "num_epoch = 15\n",
    "\n",
    "# for baseline in ['FT', 'retrain', 'SG', 'fisher_new', 'wfisher', 'GA']:\n",
    "for baseline in ['SG']:\n",
    "# for baseline in ['FT', 'retrain', 'fisher_new', 'wfisher', 'GA']:\n",
    "# for baseline in ['fisher_new', 'wfisher']:\n",
    "    tprs_ret = np.zeros(3)\n",
    "    acc_ret = []\n",
    "    for seed in range(1, 11):\n",
    "        RNG = torch.Generator().manual_seed(seed)\n",
    "        try:\n",
    "            SG_data = torch.load(f'/data1/zonglin/SG-Unlearn/result/SG_data_cifar100-15epoch/SGdata_seed_{seed}_{dataset}.pth') # TODO\n",
    "        except:\n",
    "            continue\n",
    "        # SG_data = torch.load(f'SGdata_seed_{seed}_{dataset}.pth')\n",
    "\n",
    "\n",
    "        retain_dataset = SG_data['retain']\n",
    "        test_dataset = SG_data['test']\n",
    "        val_dataset = SG_data['val']\n",
    "        forget_dataset = SG_data['forget']\n",
    "\n",
    "        retain_loader = torch.utils.data.DataLoader(\n",
    "            retain_dataset, batch_size=batch_size, shuffle=True, num_workers=2, generator=RNG)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, generator=RNG)\n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, generator=RNG)\n",
    "        forget_loader = torch.utils.data.DataLoader(\n",
    "            forget_dataset, batch_size=batch_size, shuffle=True, num_workers=2, generator=RNG)\n",
    "\n",
    "        evaluator = DefenderOPT(retain_loader, \n",
    "                                forget_loader, \n",
    "                                val_loader, \n",
    "                                test_loader,\n",
    "                                baseline_mode=1,\n",
    "                                cv=3,\n",
    "                                dim=1,\n",
    "                                seed=seed,\n",
    "                                device_id=device_id,\n",
    "                                num_class=num_classes)\n",
    "\n",
    "        if baseline == 'SG':\n",
    "            try:\n",
    "                model_path = f\"/data1/zonglin/SG-Unlearn/result/SG_data_cifar100-{num_epoch}epoch/SGcheckpoint_num_epoch_{num_epoch}_cv_3_dim_101_seed_{seed}_{dataset}.pth\"\n",
    "                weights = torch.load(model_path, map_location=device)\n",
    "            except:\n",
    "                continue\n",
    "        # elif baseline in ['GA', 'fisher_new', 'wfisher', 'IU', 'FT', 'retrain']:\n",
    "        elif baseline in ['GA', 'fisher_new', 'wfisher', 'FT', 'retrain']:\n",
    "            model_path = f\"/data1/zonglin/SG-Unlearn/result/baselines_{baseline}_{dataset}/{baseline}checkpoint_{seed}.pth.tar\" #TODO\n",
    "            weights = torch.load(model_path, map_location=device)['state_dict']\n",
    "        else:\n",
    "            raise ValueError(\"Unknown baselines.\")\n",
    "\n",
    "        model = resnet18(num_classes=num_classes)\n",
    "        model.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False)\n",
    "        model.load_state_dict(weights)\n",
    "        model.to(device)\n",
    "\n",
    "        retain_acc = DefenderOPT._evaluate_accuracy(model, retain_loader, device=device)\n",
    "        test_acc = DefenderOPT._evaluate_accuracy(model, test_loader, device=device)\n",
    "        val_acc = DefenderOPT._evaluate_accuracy(model, val_loader, device=device)\n",
    "        forget_acc = DefenderOPT._evaluate_accuracy(model, forget_loader, device=device)\n",
    "        MIA_acc, MIA_recall, MIA_auc = DefenderOPT._evaluate_MIA(model, \n",
    "                                                                 forget_loader, \n",
    "                                                                 val_loader, \n",
    "                                                                 dim=evaluator.dim,\n",
    "                                                                 seed=seed,\n",
    "                                                                 device=device,\n",
    "                                                                 save=False)\n",
    "        acc_ret.append([retain_acc, test_acc, val_acc, forget_acc, MIA_acc, MIA_auc])\n",
    "\n",
    "        forget_losses = compute_losses(model, forget_loader, device)\n",
    "        val_losses = compute_losses(model, val_loader, device)\n",
    "\n",
    "        # Since we have more forget losses than test losses, sub-sample them, to have a class-balanced dataset.\n",
    "        np.random.shuffle(forget_losses)\n",
    "        forget_losses = forget_losses[: len(val_losses)]\n",
    "\n",
    "        samples_mia = np.concatenate((val_losses, forget_losses)).reshape((-1, 1))\n",
    "        labels_mia = [0] * len(val_losses) + [1] * len(forget_losses)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(samples_mia, labels_mia, test_size=0.2, random_state=seed)\n",
    "\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X_train, y_train)\n",
    "        # Get predicted probabilities\n",
    "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "        tprs_ret += custom_tpr_at_fpr(y_test, y_prob) # true positive rates at specified false positive rates\n",
    "\n",
    "    ### get the accuracy on different subsets\n",
    "    ### RA: the accuracy on the retain set\n",
    "    ### TA: the accuracy on the test set\n",
    "    ### VA: the accuracy on the validation set\n",
    "    ### FA: the accuracy on the forget set\n",
    "    ### MIA_acc: the accuracy of the MIA \n",
    "    ### MIA_auc: the auc of the MIA\n",
    "\n",
    "    tprs_ret /= len(acc_ret)\n",
    "    acc_df = pd.DataFrame(acc_ret)\n",
    "    acc_df.columns = ['RA', 'TA', 'VA', 'FA', 'MIA_acc', 'MIA_auc']\n",
    "    os.makedirs(f'/data1/zonglin/SG-Unlearn/result/baselines_{baseline}_{dataset}/', exist_ok=True)\n",
    "    print(f'/data1/zonglin/SG-Unlearn/result/baselines_{baseline}_{dataset}/')\n",
    "    with open(f'/data1/zonglin/SG-Unlearn/result/baselines_{baseline}_{dataset}/{baseline}_{dataset}.txt', 'w') as f:\n",
    "        print_out = lambda x: print(x, file=f)\n",
    "        print_out('Average acc. (%)')\n",
    "        print_out(acc_df.mean())\n",
    "        print_out('95% confidence')\n",
    "        print_out(acc_df.sem() * 1.96)\n",
    "        print_out('tpr v.s. fpr')\n",
    "        print_out(tprs_ret * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d53d43-9eb9-4642-893c-206d7aa6a666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
